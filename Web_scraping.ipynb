{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb562589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\var_m\\anaconda3\\lib\\site-packages (0.0.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\var_m\\anaconda3\\lib\\site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\var_m\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2446aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\var_m\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\var_m\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\var_m\\anaconda3\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\var_m\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\var_m\\anaconda3\\lib\\site-packages (from requests) (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f672dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\var_m\\anaconda3\\lib\\site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\var_m\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c97f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a99293",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "num = 1\n",
    "Pirmary = []\n",
    "Urls = []\n",
    "Restaurant_list = []\n",
    "ur = []\n",
    "\n",
    "#Parameter list \n",
    "location_list = []\n",
    "Name_list = []\n",
    "Country_list = []\n",
    "Type_list = []\n",
    "Score_list = []\n",
    "Ranking_list = []\n",
    "All_Ranking_list = []\n",
    "Seat_list = []\n",
    "Price_list = []\n",
    "Check_in_list = []\n",
    "Rating_list = []\n",
    "Review_list = []\n",
    "Bookmark_list = []\n",
    "service_list = []\n",
    "check_list = []\n",
    "favor_list = []\n",
    "Type_food_list = []\n",
    "Day_Open_list = []\n",
    "Time_Open_list = []\n",
    "Pirmary_list = []\n",
    "\n",
    "#parametere loop for table\n",
    "Url_favor = []\n",
    "Url_Service =[]\n",
    "Url_Type_food = []\n",
    "Url_Day_Time_Open = []\n",
    "Url_Seat = []\n",
    "Url_Price = []\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bee2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"URL.csv\")\n",
    "Pirmary = df['ID']\n",
    "ur = df['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbbbd737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : ร้าน อุดม Seafood  ปากช่อง\n",
      "Complete page number:  1\n",
      "1001  |  ร้านอาหารในอำเภอปากช่อง /   |  ร้าน อุดม Seafood  ปากช่อง  |  ร้านในนครราชสีมา /   |  ['1']  |  ['11']  |  ['4']  |  ['47']  |  ['ร้านอาหารทะเล ในจังหวัดนครราชสีมา']  |  ['4.1']  |  ['348']  |  ['7']\n",
      "result : ร้าน Journey Cafe Khaoyai\n",
      "Complete page number:  2\n",
      "1002  |  ร้านอาหารในอำเภอปากช่อง /   |  ร้าน Journey Cafe Khaoyai  |  ร้านในนครราชสีมา /   |  ['4']  |  ['7']  |  ['4']  |  ['108']  |  ['ร้านคาเฟ่ ในจังหวัดนครราชสีมา']  |  ['4']  |  ['819']  |  ['46']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7680/302469413.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mnum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while i <= 100 :\n",
    "    #--get link in parameter for loop find data--\n",
    "    reqs = requests.get(ur[i])\n",
    "    if reqs.status_code == 200:\n",
    "        Urls.append(ur[i])\n",
    "\n",
    "        #Primary key\n",
    "        Pirmary_list.append(Pirmary[i])\n",
    "        \n",
    "        soup = bs4.BeautifulSoup(reqs.text)\n",
    "\n",
    "        #Get location Name *edit\n",
    "        Save_list = []\n",
    "        for keep in soup.find_all('li',{'class':'sc-19oew7t-3 iDLDoL'}):\n",
    "            sourse = keep.text\n",
    "            Save_list.append(sourse)\n",
    "        if len(Save_list)>2:\n",
    "            location_list.append(Save_list[4])\n",
    "            Name_list.append(Save_list[3])\n",
    "            Country_list.append(Save_list[2])\n",
    "        else:\n",
    "            location_list.append('none')\n",
    "            Name_list.append('none')\n",
    "            Country_list.append('none')            \n",
    "        print('result :', sourse)\n",
    "\n",
    "        #Get Type Restaurant   \n",
    "        Save_list = []\n",
    "        for keep in soup.find_all('span',{'class':'rg14 rg12-mWeb'}):\n",
    "            sourse = keep.text\n",
    "            Save_list.append(sourse)\n",
    "        Type_list.append(Save_list)\n",
    "\n",
    "        #Get Type Food\n",
    "        Save_list = []\n",
    "        Type_food_next = 0\n",
    "        for keep in soup.find_all('span',{'class':'sc-bdfBQB edNVkU rg16 rg14-mWeb font-highlight'}):\n",
    "            sourse = keep.text\n",
    "            Save_list.append(sourse)\n",
    "        count_Type_food = len(Save_list)\n",
    "        if count_Type_food >= 1:\n",
    "            while Type_food_next < count_Type_food:\n",
    "                Url_Type_food.append(Pirmary[i])    \n",
    "                Type_food_list.append(Save_list[Type_food_next])\n",
    "                Type_food_next += 1\n",
    "        else:\n",
    "            Url_Type_food.append(Pirmary[i]) \n",
    "            Type_food_list.append('none')                \n",
    "\n",
    "\n",
    "        #Get Score\n",
    "        Save_list = []\n",
    "        for keep in soup.find_all('div',{'class':'qkywve-1 dAZpcF bd48 text-gray-700'}):\n",
    "            sourse = keep.text\n",
    "            Save_list.append(sourse)\n",
    "        Score_list.append(Save_list)\n",
    "\n",
    "        #Get Ranking&All_Ranking\n",
    "        Save_list = []\n",
    "        Save_list2 = []\n",
    "        for keep in soup.find_all('h2',{'class':'my-auto bd16 bd14-mWeb'}):\n",
    "            sourse = keep.text\n",
    "            Save_list.append(sourse.split()[1].replace('#',''))\n",
    "            Save_list2.append(sourse.split()[3])\n",
    "        Ranking_list.append(Save_list)\n",
    "        All_Ranking_list.append(Save_list2)\n",
    "\n",
    "        #Get seat\n",
    "        Save_list = []\n",
    "        Seat_Price_Next = 0\n",
    "        for keep in soup.find_all('span',{'class':'sc-1kh6w3g-1 iflyjt'}):\n",
    "            sourse = keep.text\n",
    "            Save_list.append(sourse)\n",
    "        count_Seat_Price = len(Save_list)\n",
    "        if count_Seat_Price >= 1:\n",
    "            while Seat_Price_Next < count_Seat_Price:\n",
    "                check = Save_list[Seat_Price_Next]\n",
    "                check = check.split()[-1]              \n",
    "                if check == 'บาท)':                \n",
    "                    Price_list.append(Save_list[Seat_Price_Next])\n",
    "                    Url_Price.append(Pirmary[i])\n",
    "                if check == 'ที่นั่ง':\n",
    "                    Seat_list.append(Save_list[Seat_Price_Next])   \n",
    "                    Url_Seat.append(Pirmary[i])\n",
    "                Seat_Price_Next += 1       \n",
    "\n",
    "        #Get Check in\n",
    "        Save_list = []\n",
    "        for keep in soup.find_all('div',{'class':'StyledBaseBlock-sc-1x03vya bqisoG do39q0-0 fDzpMe font-highlight py-0-mWeb mb-0 base-block base-block do39q0-0 fDzpMe font-highlight py-0-mWeb mb-0 base-block'}):\n",
    "            keep.find('h2',{'class':'sc-1365huc-1-h2 fjvdxr bd18 bd16-mWeb mb-0'})\n",
    "            sourse = keep.text\n",
    "            Save_list.append(sourse.split()[0])\n",
    "        Check_in_list.append(Save_list)\n",
    "\n",
    "        #Get Count Rating&Review\n",
    "        Save_list = []\n",
    "        Save_list2 = []\n",
    "        for keep in soup.find_all('span',{'class':'rg16 rg14-mWeb font-highlight text-gray-500'}):\n",
    "            sourse = keep.text\n",
    "            Save_list.append(sourse.split()[0])\n",
    "            Save_list2.append(sourse.split()[2].replace('(',''))           \n",
    "        Rating_list.append(Save_list)\n",
    "        Review_list.append(Save_list2)\n",
    "\n",
    "        #Get Bookmark \n",
    "        Save_list = []\n",
    "        for keep in soup.find_all('div',{'StyledBaseBlock-sc-1x03vya bqisoG do39q0-0 fDzpMe py-0-mWeb mb-0 base-block base-block do39q0-0 fDzpMe py-0-mWeb mb-0 base-block'}):\n",
    "            keep.find('h2',{'class':'sc-1365huc-1-h2 fjvdxr bd18 bd16-mWeb mb-0'})\n",
    "            sourse = keep.text\n",
    "            Save_list.append(sourse.split()[0])\n",
    "        Bookmark_list.append(Save_list)\n",
    "\n",
    "        #Get Day_Time_Open\n",
    "        Save_list = []\n",
    "        for keep in soup.find_all('table',{'sc-1kh6w3g-8 bdBMCj'}):\n",
    "            Save_list = []\n",
    "            for findtable in keep.find_all('tr'):        \n",
    "                for find_data in findtable.find_all('td'):\n",
    "                    find_data\n",
    "                    Save_list.append(find_data.text)\n",
    "            count_Day_Time_Open = len(Save_list)\n",
    "            if count_Day_Time_Open > 1:\n",
    "                Url_Day_Time_Open.append(Pirmary[i])\n",
    "                Day_Open_list.append(Save_list[0])\n",
    "                Time_Open_list.append(Save_list[1])\n",
    "            else:\n",
    "                Url_Day_Time_Open.append(Pirmary[i])\n",
    "                Day_Open_list.append('none')\n",
    "                Time_Open_list.append('none')                \n",
    "\n",
    "\n",
    "        #Get service\n",
    "        Save_list = []\n",
    "        service_next = 0\n",
    "        for s in soup.find_all('div',{'_1weidWQshSdU3oH6Fm7DNW'}):\n",
    "            for keep in s.find_all('li'):\n",
    "                Save_list = []\n",
    "                for find_span in keep.find_all('span'):\n",
    "                    sourse = find_span\n",
    "                    Save_list.append(sourse)        \n",
    "                count_service = len(Save_list)\n",
    "                if count_service > 1:\n",
    "                    if str(Save_list[0]) == '<span class=\"zjgh1d-0 buIyWl sc-1kh6w3g-10 ixKJFC\"></span>':\n",
    "                        Url_Service.append(Pirmary[i])\n",
    "                        check_list.append('YES')\n",
    "                        service_list.append(Save_list[1].text)\n",
    "                    else:\n",
    "                        Url_Service.append(Pirmary[i])\n",
    "                        check_list.append('No')\n",
    "                        service_list.append(Save_list[1].text)                    \n",
    "                else:\n",
    "                    Url_Service.append(Pirmary[i])\n",
    "                    check_list.append('None')\n",
    "                    service_list.append('None')\n",
    "\n",
    "        #Get favor\n",
    "        Save_list = []\n",
    "        favor_next = 0\n",
    "        for keep in soup.find_all('div',{'BaseGap--1wadqs8 bgUCnb rg14 text-gray-550'}):\n",
    "            for find_div in keep.find_all('div',{'BaseGap--1wadqs8 bkqnUq'}):\n",
    "                sourse = find_div.text\n",
    "                Save_list.append(sourse)\n",
    "        #favors_list.append(Save_list)\n",
    "        count_favor = len(Save_list)\n",
    "        if count_favor > 1:\n",
    "            while favor_next < count_favor:\n",
    "                Url_favor.append(Pirmary[i])    \n",
    "                favor_list.append(Save_list[favor_next])\n",
    "                favor_next += 1\n",
    "        else:\n",
    "            Url_favor.append(Pirmary[i]) \n",
    "            favor_list.append(Save_list)\n",
    "\n",
    "        print('Complete page number: ',num)\n",
    "        print(Pirmary_list[i],' | ',Name_list[i],' | ',location_list[i],' | ',Country_list[i],' | ',Check_in_list[i],' | ',Rating_list[i],' | ',Review_list[i],' | ',Bookmark_list[i],' | ',Type_list[i],' | ',Score_list[i],' | ',All_Ranking_list[i],' | ',Ranking_list[i])\n",
    "        num += 1\n",
    "        i += 1\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfca6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame([Pirmary_list,Urls,Name_list,location_list,Country_list,Check_in_list,Rating_list,Review_list,Bookmark_list,Type_list,Score_list,All_Ranking_list,Ranking_list]).transpose()\n",
    "table.columns = ['ID','Url','Name','Location','Country','Check_in','Rating','Review','Bookmark','Type_Restaurant','Score','All_Ranking','Ranking']\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_excel('Restaurant.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c21628",
   "metadata": {},
   "outputs": [],
   "source": [
    "Favorite = pd.DataFrame([Url_favor,favor_list]).transpose()\n",
    "Favorite.columns = ['Url','Appropriate']\n",
    "Favorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Favorite.to_excel('Favorite.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Service = pd.DataFrame([Url_Service,check_list,service_list]).transpose()\n",
    "Service.columns = ['Url','Check','Service']\n",
    "Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f18c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Service.to_excel('Service.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Type_food = pd.DataFrame([Url_Type_food,Type_food_list]).transpose()\n",
    "Type_food.columns = ['Url','Type_Food']\n",
    "Type_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418891b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Type_food.to_excel('Type_food.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31784122",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day_Time_Open = pd.DataFrame([Url_Day_Time_Open,Day_Open_list,Time_Open_list]).transpose()\n",
    "Day_Time_Open.columns = ['Url','Day_Open','Time_Open']\n",
    "Day_Time_Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8560aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day_Time_Open.to_excel('Day_Time_Open.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a0aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Seat = pd.DataFrame([Url_Seat,Seat_list]).transpose()\n",
    "Seat.columns = ['Url','Seat']\n",
    "Seat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Seat.to_excel('Seat.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af43b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Price = pd.DataFrame([Url_Price,Price_list]).transpose()\n",
    "Price.columns = ['Url','Price']\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e20f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Price.to_excel('Price.xlsx',engine='openpyxl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
